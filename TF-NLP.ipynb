{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "When you see NLP, you should think of Text and Speech\\\n",
    "\n",
    "Text -> turn into numbers -> build a model -> train a model to find patterns -> use patterns(make prediction)\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data (10% of labels)\n",
    "import zipfile\n",
    "\n",
    "# Unzip the downloaded file\n",
    "zip_ref = zipfile.ZipFile(\"nlp-getting-started.zip\", \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn .csv files into pandas DataFrame's\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data doesn't have a target ( we want to try to predict this)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 7613\n",
      "Total test samples: 3263\n",
      "Total training samples: 10876\n"
     ]
    }
   ],
   "source": [
    "# How many samples total?\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total training samples: {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "???? #Krefeld: the incident happened in a chemical industry park! Emergency operations underway! A building reportly collapsed! @cnnbrk @ntvde\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Û÷Faceless body belonged to my sisterÛª: #Hiroshima #Nagasaki #nuke survivors recall horrors 70 years on ÛÓ RT News http://t.co/918EQmTkrL\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Me trying to look cute wen crush is passing by ... http://t.co/Z87zMi3Ozs\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "my brain id about to explode lmao\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "From @LeanDOTorg: Lean Thinking for Quicker Police Emergency Response Time http://t.co/suZBkyW5TT\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # Create random index not higher than the total number\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation set\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "train_df_shuffled[\"target\"].to_numpy(),\n",
    "test_size=0.1, # dedicate 10% of samples to validation set,\n",
    "random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 training sentences and their labels\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text into numbers\n",
    "\n",
    "In NLP there are two concepts for turning text into numbers\\\n",
    "<b>Tokenization</b>\\\n",
    "A straight mapping from word or sentence to a numerical value\\\n",
    "<b>Embeddings</b>\\\n",
    "Representation of natural language which can be learned. Representation comes in the form of a feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=None, # how many words in the vocabulary\n",
    "standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "split=\"whitespace\", # how to split tokens\n",
    "ngrams=None, # create groups of n-words\n",
    "output_mode=\"int\", # how to make tokens to numbers\n",
    "output_sequence_length=None) # how long should the ouput sequence of tokens be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average number of tokens (words) in training tweets\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup another text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be\n",
    "\n",
    "text_vectorizer =  tf.keras.layers.TextVectorization(max_tokens=max_vocab_length,\n",
    "output_mode=\"int\",\n",
    "output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[  68,   12,  106,   19,    9, 8839,    1,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create sample sentence and tokenize it\n",
    "sample_sentence = \"do you know this is sample sentence?\"\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notice output_sequence_length = 15, so no matter the size of the sequence we pass to text_vectorizer, it always return a sequence with length 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "@__ScrambledEggs calling it now: KIA gets banned or quarantined before month's end    \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[8739, 1705,   15,   48,    1,  742,  793,   53,  433,  239, 1119,\n",
       "         304,    0,    0,    0]], dtype=int64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose random sentence\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "    \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in vocab: 10000\n",
      "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "top_5_words = words_in_vocab[:5] # most common tokens\n",
    "bottom_5_words = words_in_vocab[-5:] # Least common tokens\n",
    "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"Top 5 most common words: {top_5_words}\")\n",
    "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Embedding using an Embedding Layer\n",
    "Powerful thing about an embedding is it can be learned during training. Tokenization cannot learn(is static)\\\n",
    "<b>Input_dim</b> - The size of the vocabulary\\\n",
    "<b>Output_dim</b> - The size of the output embedding vector\\\n",
    "<b>Embeddings_initializer </b>- How to initialize the embedding matrix\\\n",
    "<b>Input_length</b> - Length of sequences being passed to embedding layer\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x110ae88c790>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # itialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\")\n",
    "embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created embedding tensorflow layer. We can use it as part of a model, meaning its parameters(word represent) can be updated and improved as it learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "IÛªve just signed up for the Detonate Nottingham Autumn Launch Party. Register here: http://t.co/Km8uCIHrRN    \n",
      "\n",
      "Embedded version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.01387816, -0.04037098,  0.02454552, ...,  0.04164531,\n",
       "          0.03675271,  0.01165976],\n",
       "        [-0.03624376,  0.04096097,  0.00048   , ..., -0.0216538 ,\n",
       "          0.00666716,  0.01672911],\n",
       "        [-0.01218056,  0.03776804, -0.042695  , ...,  0.02196519,\n",
       "         -0.00387148,  0.04090047],\n",
       "        ...,\n",
       "        [ 0.01193949, -0.04389204,  0.00746778, ..., -0.00726794,\n",
       "         -0.03415887,  0.00991349],\n",
       "        [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "          0.03332629,  0.02803668],\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from training set\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "    \\n\\nEmbedded version:\")\n",
    "\n",
    "# Embed the random sentence (turn it into numerical representation)\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([-0.01387816, -0.04037098,  0.02454552, -0.01573527,  0.0351646 ,\n",
       "        0.04676745, -0.03681671,  0.0279292 ,  0.03961677,  0.00186767,\n",
       "       -0.04730154, -0.00420477, -0.04449501, -0.041125  , -0.03358554,\n",
       "        0.04066365,  0.00082291,  0.02987077, -0.02802328, -0.03749008,\n",
       "       -0.028752  , -0.02913274, -0.00316538,  0.04508562,  0.0367418 ,\n",
       "       -0.04710525, -0.00194141, -0.0357183 ,  0.02646628, -0.04643911,\n",
       "       -0.03757938, -0.01348056, -0.02931099, -0.03154454,  0.04608564,\n",
       "        0.00665252, -0.03576834, -0.03499713,  0.03302273,  0.00192929,\n",
       "        0.02728982,  0.01253692, -0.04105368,  0.01293231,  0.02215796,\n",
       "       -0.00359243, -0.02030566, -0.04435338, -0.00800883, -0.04745622,\n",
       "       -0.02592883,  0.0076615 ,  0.02814205, -0.02680153,  0.03866103,\n",
       "       -0.00036297, -0.02435836, -0.0322661 ,  0.02505152, -0.04081105,\n",
       "        0.01568684,  0.04301989,  0.00137084,  0.00564011, -0.00229055,\n",
       "       -0.02817329,  0.01382038, -0.00323945, -0.02741213, -0.03359775,\n",
       "       -0.01763953, -0.02311863,  0.0360692 , -0.00812539, -0.01517296,\n",
       "        0.01703819, -0.04201552,  0.00450896,  0.02808524, -0.01347214,\n",
       "       -0.02755686, -0.01025525, -0.02240102,  0.0462273 ,  0.00783683,\n",
       "       -0.04605196,  0.00768717,  0.02340243, -0.03985362, -0.03442067,\n",
       "       -0.00716643,  0.03377973, -0.04189435, -0.03376776, -0.02480745,\n",
       "       -0.03908502, -0.00546223, -0.04020512,  0.02755708,  0.00470669,\n",
       "        0.03523829, -0.03303166, -0.03335221,  0.01218079, -0.02167397,\n",
       "       -0.02576004, -0.00576583, -0.01603081, -0.02244005,  0.02451072,\n",
       "        0.01843852, -0.02384288, -0.01354995, -0.02088195, -0.01512402,\n",
       "       -0.02893764,  0.04939195,  0.03050024,  0.02220135,  0.00462693,\n",
       "       -0.03462262, -0.01030457,  0.01518473,  0.0077774 , -0.04255501,\n",
       "        0.04164531,  0.03675271,  0.01165976], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out a single token's embedding\n",
    "sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what our computer sees each word as. When our model looks for patterns in different samples, these values will be updated as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling a text dataset\n",
    "\n",
    "We will try out a list of models and see which one performed best\\\n",
    "Naive Bayes\\\n",
    "Feed-Forward neural network\\\n",
    "LSTM Model\\\n",
    "GRU model\\\n",
    "Bidirectional-LSTM Model\\\n",
    "1D Convolutional Neural Network\\\n",
    "TensorFlow Hub Pretrained Feature Extractor\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modeling pipeline\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an evaluation function for our model experiments\n",
    "\n",
    "Let's create helper function which takes an array of predictions and ground truth labels and computes the following\\\n",
    "Accuracy\\\n",
    "Precision\\\n",
    "Recall\\\n",
    "F1-Score\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binary classifcation model.\n",
    "    \n",
    "    Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "    \"\"\"\n",
    "    # Calculate model accuracy\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {'accuracy': model_accuracy,\n",
    "                     \"precision\": model_precision,\n",
    "                     \"recall\": model_recall,\n",
    "                     \"f1\": model_f1}\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: A simple dense model Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to save TensorBoard Logs\n",
    "SAVE_DIR = \"model_logs\"\n",
    "\n",
    "# Build model with the Functional API\n",
    "from tensorflow.keras import layers\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\") # Inputs are 1-dimensional strings\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "x = embedding(x) # create an embedding of the numerized numbers\n",
    "x = layers.GlobalAveragePooling1D()(x) # Lower the dimensionality of the embedding\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x) # create the output layer, want binary outputs\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get summary of the model\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 5ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 5ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 4ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model_1_history = model_1.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47668489813804626, 0.787401556968689]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the results\n",
    "model_1.evaluate(val_sentences, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4048997 ],\n",
       "       [0.74437505],\n",
       "       [0.99789494],\n",
       "       [0.1089061 ],\n",
       "       [0.1114305 ],\n",
       "       [0.9355648 ],\n",
       "       [0.9134605 ],\n",
       "       [0.99253464],\n",
       "       [0.97157174],\n",
       "       [0.26569813]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions (these come back in the form of probabilities)\n",
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn prediction probabilities into a single-dimension tensor of floats\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n",
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks\n",
    "Simply put: Use information from the past to help you with the future. Take an input and compute an output based on all previous inputs\\\n",
    "\n",
    "<b>One to one:</b> One input, one output, such as image classification\\\n",
    "<b>One to many:</b> One input, many output, such as image captioning\\\n",
    "<b>Many to one:</b> Many input, one output, such as text classification\\\n",
    "<b>Many to Many:</b> Many input, Many output, such as machine translation\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 128)\n",
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "# Model 2: LSTM\n",
    "# Set random seed and create embedding layer\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                    output_dim=128,\n",
    "                                    embeddings_initializer=\"uniform\",\n",
    "                                    input_length=max_length,\n",
    "                                    name='embedding_2')\n",
    "\n",
    "# Create LSTM Model\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_2_embedding(x)\n",
    "print(x.shape)\n",
    "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
    "print(x.shape)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name='model_2_LSTM')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_2.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 8ms/step - loss: 0.5100 - accuracy: 0.7415 - val_loss: 0.4567 - val_accuracy: 0.7835\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3175 - accuracy: 0.8717 - val_loss: 0.5139 - val_accuracy: 0.7756\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.2201 - accuracy: 0.9152 - val_loss: 0.5858 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.6040 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.8748 - val_accuracy: 0.7507\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_2_history = model_2.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.00710386],\n",
       "        [0.7871485 ],\n",
       "        [0.99963677],\n",
       "        [0.05668796],\n",
       "        [0.00257999],\n",
       "        [0.9996238 ],\n",
       "        [0.92141753],\n",
       "        [0.9997992 ],\n",
       "        [0.99949515],\n",
       "        [0.66567504]], dtype=float32))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation dataset\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs.shape, model_2_pred_probs[:10] # view the first 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round out predictions and reduce to 1-dimensional array\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.06561679790026,\n",
       " 'precision': 0.7510077975908164,\n",
       " 'recall': 0.7506561679790026,\n",
       " 'f1': 0.7489268622514025}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate LSTM model results\n",
    "model_2_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_2_preds)\n",
    "model_2_results                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: GRU\n",
    "GRU network has similar feature to an LSTM cell but has less parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_3\")\n",
    "\n",
    "# Build an RNN using the GRU cell\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_3_embedding(x)\n",
    "x = layers.GRU(64)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile GRU model\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3_GRU\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 64)                37248     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,317,313\n",
      "Trainable params: 1,317,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of the GRU model\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice LSTM model has more trainable parameters than the GRU cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 8ms/step - loss: 0.5242 - accuracy: 0.7314 - val_loss: 0.4553 - val_accuracy: 0.7769\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.3195 - accuracy: 0.8695 - val_loss: 0.4937 - val_accuracy: 0.7808\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.2197 - accuracy: 0.9183 - val_loss: 0.5607 - val_accuracy: 0.7743\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.1599 - accuracy: 0.9441 - val_loss: 0.6220 - val_accuracy: 0.7782\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.1221 - accuracy: 0.9584 - val_loss: 0.6204 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "model_3_history = model_3.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((762, 1),\n",
       " array([[0.3334687 ],\n",
       "        [0.8773777 ],\n",
       "        [0.9980236 ],\n",
       "        [0.11562637],\n",
       "        [0.01236299],\n",
       "        [0.9925592 ],\n",
       "        [0.62132007],\n",
       "        [0.9981329 ],\n",
       "        [0.9982368 ],\n",
       "        [0.50158083]], dtype=float32))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the validation data\n",
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs.shape, model_3_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to prediction classes\n",
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.77165354330708,\n",
       " 'precision': 0.7675450859410361,\n",
       " 'recall': 0.7677165354330708,\n",
       " 'f1': 0.7667932666650168}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_3 results\n",
    "model_3_results = calculate_results(y_true=val_labels,\n",
    "                                    y_pred=model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Bidirectional RNN model\n",
    "Standard RNN process a sequence from left to right, where bidirectional RNN will process the sequence from left to right and then again from right to left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed and create embedding layer\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
    "                                     output_dim=128,\n",
    "                                     embeddings_initializer=\"uniform\",\n",
    "                                     input_length=max_length,\n",
    "                                     name=\"embedding_4\")\n",
    "\n",
    "# Build a Bidrectional RNN in TensorFlow\n",
    "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
    "x = text_vectorizer(inputs)\n",
    "x = model_4_embedding(x)\n",
    "\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both way so double the parameters to train\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidrectional\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss='binary_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidrectional\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 15, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 12ms/step - loss: 0.5093 - accuracy: 0.7481 - val_loss: 0.4606 - val_accuracy: 0.7795\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.3135 - accuracy: 0.8708 - val_loss: 0.5144 - val_accuracy: 0.7690\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2150 - accuracy: 0.9178 - val_loss: 0.5626 - val_accuracy: 0.7677\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1523 - accuracy: 0.9469 - val_loss: 0.6365 - val_accuracy: 0.7769\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.1083 - accuracy: 0.9639 - val_loss: 0.6510 - val_accuracy: 0.7664\n"
     ]
    }
   ],
   "source": [
    "# Fit the model (takes longer because of the bidirectional layers)\n",
    "model_4_history = model_4.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03995823],\n",
       "       [0.8280176 ],\n",
       "       [0.99842227],\n",
       "       [0.13524732],\n",
       "       [0.00311263],\n",
       "       [0.9921962 ],\n",
       "       [0.9553725 ],\n",
       "       [0.99945563],\n",
       "       [0.998982  ],\n",
       "       [0.2814204 ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with bidirectional RNN on the validation data\n",
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.64041994750657,\n",
       " 'precision': 0.7665895370389821,\n",
       " 'recall': 0.7664041994750657,\n",
       " 'f1': 0.7651213533864446}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate bidirectional RNN model results\n",
    "model_4_results = calculate_results(val_labels, model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Embeddings (Transfer learning for NLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = [\"There's a flood in my street!\"]\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When input_signature is provided, all inputs to the Python function must be convertible to tensors:\n  inputs: (\n    [[\"There's a flood in my street!\"], 'When you call the universal sentence encoder on a sentence, it turns it into numbers.'])\n  input_signature: (\n    TensorSpec(shape=<unknown>, dtype=tf.string, name=None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2879\u001b[0m, in \u001b[0;36m_convert_inputs_to_signature\u001b[1;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2877'>2878</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2878'>2879</a>\u001b[0m   flatten_inputs[index] \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2879'>2880</a>\u001b[0m       value, dtype_hint\u001b[39m=\u001b[39;49mspec\u001b[39m.\u001b[39;49mdtype)\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2880'>2881</a>\u001b[0m   need_packing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/profiler/trace.py?line=161'>162</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/profiler/trace.py?line=162'>163</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/ops.py?line=1564'>1565</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/ops.py?line=1565'>1566</a>\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/ops.py?line=1567'>1568</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:346\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=344'>345</a>\u001b[0m _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=345'>346</a>\u001b[0m \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=175'>176</a>\u001b[0m \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=176'>177</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=177'>178</a>\u001b[0m \u001b[39mNote: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=268'>269</a>\u001b[0m \u001b[39m  ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=269'>270</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=270'>271</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=271'>272</a>\u001b[0m                       allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=281'>282</a>\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=282'>283</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=284'>285</a>\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=306'>307</a>\u001b[0m \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=307'>308</a>\u001b[0m t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=308'>309</a>\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=104'>105</a>\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/framework/constant_op.py?line=105'>106</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\16178\\Desktop\\DataScienceStuff\\TF-NLP.ipynb Cell 70'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/16178/Desktop/DataScienceStuff/TF-NLP.ipynb#ch0000071?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/16178/Desktop/DataScienceStuff/TF-NLP.ipynb#ch0000071?line=2'>3</a>\u001b[0m embed \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mhttps://tfhub.dev/google/universal-sentence-encoder/4\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m# load Universal Sentence Encoder\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/16178/Desktop/DataScienceStuff/TF-NLP.ipynb#ch0000071?line=3'>4</a>\u001b[0m embed_samples \u001b[39m=\u001b[39m embed([sample_sentence,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/16178/Desktop/DataScienceStuff/TF-NLP.ipynb#ch0000071?line=4'>5</a>\u001b[0m                       \u001b[39m\"\u001b[39;49m\u001b[39mWhen you call the universal sentence encoder on a sentence, it turns it into numbers.\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/16178/Desktop/DataScienceStuff/TF-NLP.ipynb#ch0000071?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(embed_samples[\u001b[39m0\u001b[39m][:\u001b[39m50\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:664\u001b[0m, in \u001b[0;36m_call_attribute\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/saved_model/load.py?line=662'>663</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_attribute\u001b[39m(instance, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/saved_model/load.py?line=663'>664</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m instance\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=881'>882</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=883'>884</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=884'>885</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=886'>887</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=887'>888</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:953\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=951'>952</a>\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[1;32m--> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=952'>953</a>\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=953'>954</a>\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=954'>955</a>\u001b[0m   \u001b[39m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=955'>956</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn\u001b[39m.\u001b[39m_call_flat(\n\u001b[0;32m    <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/def_function.py?line=956'>957</a>\u001b[0m       filtered_flat_args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn\u001b[39m.\u001b[39mcaptured_inputs)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2786\u001b[0m, in \u001b[0;36mFunctionSpec.canonicalize_function_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2783'>2784</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2784'>2785</a>\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs\n\u001b[1;32m-> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2785'>2786</a>\u001b[0m   inputs, flat_inputs, filtered_flat_inputs \u001b[39m=\u001b[39m _convert_inputs_to_signature(\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2786'>2787</a>\u001b[0m       inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_signature, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_input_signature)\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2788'>2789</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(flat_inputs)\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2790'>2791</a>\u001b[0m \u001b[39mreturn\u001b[39;00m inputs, kwargs, flat_inputs, filtered_flat_inputs\n",
      "File \u001b[1;32mc:\\Users\\16178\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2883\u001b[0m, in \u001b[0;36m_convert_inputs_to_signature\u001b[1;34m(inputs, input_signature, flat_input_signature)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2880'>2881</a>\u001b[0m       need_packing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2881'>2882</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2882'>2883</a>\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWhen input_signature is provided, all inputs to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2883'>2884</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mthe Python function must be convertible to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2884'>2885</a>\u001b[0m                        \u001b[39m\"\u001b[39m\u001b[39mtensors:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2885'>2886</a>\u001b[0m                        format_error_message(inputs, input_signature))\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2887'>2888</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39mnot\u001b[39;00m spec\u001b[39m.\u001b[39mis_compatible_with(other) \u001b[39mfor\u001b[39;00m spec, other \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2888'>2889</a>\u001b[0m     flat_input_signature,\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2889'>2890</a>\u001b[0m     flatten_inputs)):\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2890'>2891</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPython inputs incompatible with input_signature:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/16178/anaconda3/envs/ml/lib/site-packages/tensorflow/python/eager/function.py?line=2891'>2892</a>\u001b[0m                    format_error_message(inputs, input_signature))\n",
      "\u001b[1;31mValueError\u001b[0m: When input_signature is provided, all inputs to the Python function must be convertible to tensors:\n  inputs: (\n    [[\"There's a flood in my street!\"], 'When you call the universal sentence encoder on a sentence, it turns it into numbers.'])\n  input_signature: (\n    TensorSpec(shape=<unknown>, dtype=tf.string, name=None))"
     ]
    }
   ],
   "source": [
    "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
    "embed_samples = embed([sample_sentence,\n",
    "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each sentence has been encoded into a 512 dimension vector\n",
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
    "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        input_shape=[], # shape of inputs coming to our model \n",
    "                                        dtype=tf.string, # data type of inputs coming to the USE layer\n",
    "                                        trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
    "                                        name=\"USE\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6_USE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "USE (KerasLayer)             (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create model using the Sequential API\n",
    "model_6 = tf.keras.Sequential([\n",
    "  sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
    "  layers.Dense(64, activation=\"relu\"),\n",
    "  layers.Dense(1, activation=\"sigmoid\")\n",
    "], name=\"model_6_USE\")\n",
    "\n",
    "# Compile model\n",
    "model_6.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 5s 16ms/step - loss: 0.5038 - accuracy: 0.7859 - val_loss: 0.4477 - val_accuracy: 0.7992\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.4146 - accuracy: 0.8136 - val_loss: 0.4368 - val_accuracy: 0.8071\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.3997 - accuracy: 0.8219 - val_loss: 0.4327 - val_accuracy: 0.8084\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.3922 - accuracy: 0.8260 - val_loss: 0.4281 - val_accuracy: 0.8176\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.3856 - accuracy: 0.8291 - val_loss: 0.4297 - val_accuracy: 0.8176\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier on top of pretrained embeddings\n",
    "model_6_history = model_6.fit(train_sentences,\n",
    "                              train_labels,\n",
    "                              epochs=5,\n",
    "                              validation_data=(val_sentences, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1616196 ],\n",
       "       [0.75651956],\n",
       "       [0.98830557],\n",
       "       [0.20484091],\n",
       "       [0.7304971 ],\n",
       "       [0.6591135 ],\n",
       "       [0.98067147],\n",
       "       [0.9770989 ],\n",
       "       [0.9271192 ],\n",
       "       [0.08704827]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with USE TF Hub model\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert prediction probabilities to labels\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.75853018372703,\n",
       " 'precision': 0.8202616926815424,\n",
       " 'recall': 0.8175853018372703,\n",
       " 'f1': 0.8159820561172786}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model 6 performance metrics\n",
    "model_6_results = calculate_results(val_labels, model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on the test dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 1, Prob: 0.565223753452301\n",
      "Text:\n",
      "@johndavidblake Winds me up to see 95% 'whites' held up as 'black' as if just a trace of flattened nose or curly hair is impure.\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.20992141962051392\n",
      "Text:\n",
      "Pelling hotels: no strings concealment from straight a rejuvenati???ng evacuation day: pqhaxp\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.2170921266078949\n",
      "Text:\n",
      "?please read casualty fans?\n",
      "Let us know &amp; help spread the word by retweeting! DM me or @ScriptetteSar for more info?? http://t.co/HDrBTJRoHb\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 1, Prob: 0.9861007332801819\n",
      "Text:\n",
      "@61_alvin @Craigyb74 @nomar4eva @Shahasda80 @wherepond @trensabby @parallelpond the wall Israel erected has stopped suicide bombing?\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.11619587987661362\n",
      "Text:\n",
      "@cameron13131313 @OtooleDalton @averywelch23 @otoole1055 first of all you can't 'hit stick' shit.. Second I'm body bagging you on sight ??????\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.09346773475408554\n",
      "Text:\n",
      "@itsTiimothy bhill bruh you can obliterate beez\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.07152983546257019\n",
      "Text:\n",
      "@JanelleBrown117 YES! We are comrades in sweat-seeking calorie-burning cardio-torture! We need all the support we can get- smile nod wave\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.059386901557445526\n",
      "Text:\n",
      "@MarquisDeSpade You can tell yer sins to me. I won't judge you. Take your clothes off and we can sing a hymn. Let's do Abba .@TORNADO_CHICK\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.12795908749103546\n",
      "Text:\n",
      "@noobde @comingsoonnet YEEESSSS!!!! I will buy him twice!! No KP2 jus release kombatants stages alternate kostumes and fatalities at will\n",
      "\n",
      "----\n",
      "\n",
      "Pred: 0, Prob: 0.08121298998594284\n",
      "Text:\n",
      "Big Papi just demolished that ball. \n",
      "\n",
      "#BOSvsNYY\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the test dataset\n",
    "test_sentences = test_df['text'].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "for test_sample in test_samples:\n",
    "    pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be a list\n",
    "    pred = tf.round(pred_prob)\n",
    "    print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n{test_sample}\\n\")\n",
    "    print(\"----\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on Tweets from the wild\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Tweet into string\n",
    "daniels_tweet = \"Life like an ensemble: take the best choices from others and make your own\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 0.0 (not real disaster) Prob: 0.04917609691619873\n",
      "Text:\n",
      "Life like an ensemble: take the best choices from others and make your own\n"
     ]
    }
   ],
   "source": [
    "def predict_on_sentence(model, sentence):\n",
    "    \"\"\"\n",
    "    use model to make prediction on sentence.\n",
    "    returns the sentence, the predicted label and the prediction probability\"\"\"\n",
    "    pred_prob = model.predict([sentence])\n",
    "    pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
    "    print(f\"Pred: {pred_label}\", \"(real_disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n",
    "    print(f\"Text:\\n{sentence}\")\n",
    "\n",
    "# Make a prediction on Tweet from the wild\n",
    "predict_on_sentence(model=model_6, # use the USE model\n",
    "                    sentence=daniels_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n",
    "beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
    "\n",
    "# Source - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n",
    "beirut_tweet_2 = \"#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 1.0 (real_disaster) Prob: 0.9664455056190491\n",
      "Text:\n",
      "Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"
     ]
    }
   ],
   "source": [
    "# Predict on diaster Tweet 1\n",
    "predict_on_sentence(model=model_6, \n",
    "                    sentence=beirut_tweet_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: 1.0 (real_disaster) Prob: 0.9755615592002869\n",
      "Text:\n",
      "#Beirut declared a “devastated city”, two-week state of emergency officially declared. #Lebanon\n"
     ]
    }
   ],
   "source": [
    "# Predict on diaster Tweet 2\n",
    "predict_on_sentence(model=model_6, \n",
    "                    sentence=beirut_tweet_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d76396febbd0a733882b1458c3ee4a5c8a662d67033c926e5be313f23d66902e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
